{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apache_beam\n",
    "!pip install openslide\n",
    "# !pip install librsvg\n",
    "# !pip install libiconv\n",
    "!apt-get update && apt-get install -y libvips libvips-dev\n",
    "!pip install pyvips\n",
    "# !pip install --upgrade pyvips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.ml.inference.base import ModelHandler\n",
    "from apache_beam.ml.inference.base import RunInference\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import typing as npt\n",
    "from PIL import Image\n",
    "\n",
    "from typing import (\n",
    "    Iterable,\n",
    "    NamedTuple,\n",
    "    NewType,\n",
    "    Sequence,\n",
    "    Optional,\n",
    "    Dict, Any, List\n",
    ")\n",
    "import csv\n",
    "import openslide\n",
    "import pyvips\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/kaggle/input/mayo-clinic-strip-ai/train.csv' #all images\n",
    "csv_path = '/kaggle/input/train-csv-3/train_csv_2.csv' #1 image - large\n",
    "csv_path = '/kaggle/input/d/adityashukla1/train-small-2/train_small.csv' #1 image - medium\n",
    "csv_path = '/kaggle/input/train-csv-4/train_csv_3.csv' #1 image - small\n",
    "\n",
    "tiff_files_location = '/kaggle/input/mayo-clinic-strip-ai/train'\n",
    "image_path = '/kaggle/input/mayo-clinic-strip-ai/train/006388_0.tif'\n",
    "train_csv = pd.read_csv('/kaggle/input/mayo-clinic-strip-ai/train.csv')\n",
    "\n",
    "output_prefix = 'patient_info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_patient_info(row_dict):\n",
    "    return (row_dict['patient_id'], row_dict)\n",
    "\n",
    "class PatientDataCombineFn(beam.CombineFn):\n",
    "    def create_accumulator(self):\n",
    "        return {\n",
    "            'center_ids': set(),\n",
    "            'labels': set(),\n",
    "            'image_ids': []\n",
    "        }\n",
    "\n",
    "    def add_input(self, acc, element):\n",
    "        acc['center_ids'].add(element['center_id'])\n",
    "        if 'label' in element:\n",
    "            acc['labels'].add(element['label'])\n",
    "        acc['image_ids'].append(element['image_id'])\n",
    "        return acc\n",
    "\n",
    "    def merge_accumulators(self, accs):\n",
    "        result = self.create_accumulator()\n",
    "        for acc in accs:\n",
    "            result['center_ids'].update(acc['center_ids'])\n",
    "            result['labels'].update(acc['labels'])\n",
    "            result['image_ids'].extend(acc['image_ids'])\n",
    "        return result\n",
    "\n",
    "    def extract_output(self, acc):\n",
    "        return {\n",
    "            'center_id': list(acc['center_ids'])[0],\n",
    "            'label': list(acc['labels'])[0] if acc['labels'] else None,\n",
    "            'image_ids': acc['image_ids']\n",
    "        }\n",
    "\n",
    "def select_image_id(patient_id, record):\n",
    "    return record['image_id'], record\n",
    "\n",
    "def load_downscaled_image(local_file_path, downsample_ratio=16):\n",
    "    print(f'>> Load original image: {local_file_path}')\n",
    "    full_img = pyvips.Image.new_from_file(local_file_path)\n",
    "    print(f\">> Original image size: h-{full_img.height} w-{full_img.width}\")\n",
    "    scaled_down_image = full_img.resize(1 / downsample_ratio).numpy()\n",
    "    # print(f'>> scaled down image: {scaled_down_image}')\n",
    "    return scaled_down_image\n",
    "\n",
    "def extract_tiles(input_image_path, non_empty_tile_indices, tile_size=448):\n",
    "    print(f\"\"\">> extract tiles: {input_image_path}\n",
    ">> non-empty tile indices: {non_empty_tile_indices}\"\"\")\n",
    "    size = (tile_size, tile_size)\n",
    "    with openslide.open_slide(input_image_path) as slide:\n",
    "        for row, column in non_empty_tile_indices:\n",
    "            left = column * tile_size\n",
    "            top = row * tile_size\n",
    "            position = (left, top)\n",
    "            tile_img = slide.read_region(position, 0, size).convert(\"RGB\")\n",
    "            yield tile_img\n",
    "\n",
    "def produce_tiles(image_id, metadata, tiff_files_location, max_tiles=None):\n",
    "    image_path = os.path.join(tiff_files_location, f\"{image_id}.tif\")\n",
    "    downsample_ratio = 16\n",
    "    tile_size = 448\n",
    "    background_threshold = 0.7\n",
    "\n",
    "    # Load downscaled image\n",
    "    scaled_image = load_downscaled_image(image_path, downsample_ratio)\n",
    "    print(f'>> scaled_image shape: {scaled_image.shape}')\n",
    "    height, width, _ = scaled_image.shape\n",
    "    rows = height // tile_size\n",
    "    cols = width // tile_size\n",
    "    print(f\"rows and cols: {rows, cols}\")\n",
    "\n",
    "    non_empty_tiles = []\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            top = row * tile_size\n",
    "            left = col * tile_size\n",
    "            tile = scaled_image[top:top + tile_size, left:left + tile_size]\n",
    "            # Determine background pixels\n",
    "            background_pixels = np.all(tile > 190, axis=2)\n",
    "            background_ratio = np.mean(background_pixels)\n",
    "            print(f\"\"\">> bg ratio: {background_ratio}\n",
    ">> bg threshold: {background_threshold}\"\"\"\n",
    "            )\n",
    "            if background_ratio < background_threshold:\n",
    "                non_empty_tiles.append((row, col))\n",
    "\n",
    "    if max_tiles:\n",
    "        non_empty_tiles = non_empty_tiles[:max_tiles]\n",
    "\n",
    "    for tile_img in extract_tiles(image_path, non_empty_tiles, tile_size):\n",
    "        print(f\">> produce tiles: {image_path}\")\n",
    "        yield {\n",
    "            'image_id': image_id,\n",
    "            'patient_id': metadata['patient_id'],\n",
    "            'center_id': metadata['center_id'],\n",
    "            'label': metadata.get('label'),\n",
    "            'tile': tile_img\n",
    "        }\n",
    "\n",
    "def convert_to_tile_entry(tile_dict):\n",
    "    tile_img: Image.Image = tile_dict[\"tile\"]\n",
    "    np_image: np.ndarray = np.array(tile_img, dtype=np.uint8)\n",
    "    return TileEntry(\n",
    "        patient_id=tile_dict[\"patient_id\"],\n",
    "        image=np_image\n",
    "    )\n",
    "\n",
    "\n",
    "PatientId = NewType(\"PatientId\", str)\n",
    "Image = npt.NDArray[np.uint8]\n",
    "\n",
    "class TileEntry(NamedTuple):\n",
    "    \"\"\"Schema for a tile entry.\"\"\"\n",
    "\n",
    "    patient_id: PatientId\n",
    "    image: Image\n",
    "\n",
    "\n",
    "class Embedding(NamedTuple):\n",
    "    \"\"\"Schema for aggregated embeddings.\"\"\"\n",
    "\n",
    "    max_embedding: tf.Tensor\n",
    "    avg_embedding: tf.Tensor\n",
    "\n",
    "\n",
    "class EmbeddingEntry(NamedTuple):\n",
    "    \"\"\"Schema for prediction entry.\"\"\"\n",
    "\n",
    "    patient_id: PatientId\n",
    "    embedding: Embedding\n",
    "\n",
    "\n",
    "def embed_tiles(\n",
    "    model: tf.keras.Model,\n",
    "    tiles_batch: Sequence[Image],\n",
    ") -> Iterable[Embedding]:\n",
    "    \"\"\"\n",
    "    Run a batch of input images through EfNet\n",
    "    to generate aggregated embeddings.\n",
    "    \"\"\"\n",
    "    # convert from NumPy to TensorFlow\n",
    "    input_tensor = tf.ensure_shape(\n",
    "        tf.convert_to_tensor(tiles_batch),\n",
    "        [None, 224 * 2, 224 * 2, 3],\n",
    "    )\n",
    "    # The input tile is twice as big as needed\n",
    "    # for EfNet - we scaled it down 2x here.\n",
    "    resized_input_tensor = tf.image.resize(input_tensor, [224, 224])\n",
    "    # generate embeddings using EfNet\n",
    "    results = model(resized_input_tensor, training=False)\n",
    "    avg_embeddings = tf.ensure_shape(results[\"avg\"], [None, 1280])\n",
    "    max_embeddings = tf.ensure_shape(results[\"max\"], [None, 1280])\n",
    "    # wrap the results\n",
    "    for avg_embedding, max_embedding in zip(avg_embeddings, max_embeddings):\n",
    "        yield Embedding(avg_embedding=avg_embedding, max_embedding=max_embedding)\n",
    "\n",
    "\n",
    "class TileEmbeddingModelHandler(\n",
    "    ModelHandler[TileEntry, EmbeddingEntry, tf.keras.Model]\n",
    "):\n",
    "    \"\"\"Wrapper around EfficientNet embedding.\"\"\"\n",
    "\n",
    "    def load_model(self) -> tf.keras.Model:\n",
    "        \"\"\"Prepare an EfNet aggregation model for tile images.\"\"\"\n",
    "        # The model will consume 224x224 RGB images\n",
    "        image = tf.keras.layers.Input(\n",
    "            shape=(224, 224, 3), name=\"image\", dtype=tf.float32\n",
    "        )\n",
    "        # We use EfNet B0 without top layers for embedding\n",
    "        backbone = tf.keras.applications.EfficientNetB0(\n",
    "            include_top=False, weights=\"imagenet\", input_tensor=image\n",
    "        )\n",
    "        # To save on compute resources, we won't fine-tune the EfNet backbone\n",
    "        backbone.trainable = False\n",
    "        # The backbone output has shape [<batch size>, 7, 7, 1280]\n",
    "        # We generate two aggregations over the backbone output\n",
    "        # to obtain a [<batch size>, 1280] shape\n",
    "        avg_pool = tf.keras.layers.GlobalAveragePooling2D()(backbone.output)\n",
    "        max_pool = tf.keras.layers.GlobalMaxPooling2D()(backbone.output)\n",
    "        model = tf.keras.Model(\n",
    "            image, {\"avg\": avg_pool, \"max\": max_pool}, name=\"EfficientNet\"\n",
    "        )\n",
    "        model.compile()\n",
    "        return model\n",
    "\n",
    "    def run_inference(\n",
    "        self,\n",
    "        batch: Sequence[TileEntry],\n",
    "        model: tf.keras.Model,\n",
    "        inference_args: Optional[Dict[str, Any]] = None,\n",
    "    ) -> Iterable[EmbeddingEntry]:\n",
    "        \"\"\"Run inference using the loaded model.\"\"\"\n",
    "        # Extract just the tile images from the input batch\n",
    "        input_images = [tile.image for tile in batch]\n",
    "        # Embed tile images using EfNet\n",
    "        embeddings = embed_tiles(model, input_images)\n",
    "        # Wrap the resulting embeddings together with the patient identifier\n",
    "        for tile, embedding in zip(batch, embeddings):\n",
    "            yield EmbeddingEntry(patient_id=tile.patient_id, embedding=embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineEmbeddingsFn(beam.CombineFn):\n",
    "    def create_accumulator(self):\n",
    "        return []\n",
    "\n",
    "    def add_input(self, accumulator, embedding_entry: EmbeddingEntry):\n",
    "        accumulator.append(embedding_entry.embedding)\n",
    "        return accumulator\n",
    "\n",
    "    def merge_accumulators(self, accumulators):\n",
    "        merged = []\n",
    "        for acc in accumulators:\n",
    "            merged.extend(acc)\n",
    "        return merged\n",
    "\n",
    "    def extract_output(self, embeddings: list[Embedding]):\n",
    "        if not embeddings:\n",
    "            return None\n",
    "\n",
    "        avg_embeddings = np.stack([e.avg_embedding.numpy() for e in embeddings])\n",
    "        max_embeddings = np.stack([e.max_embedding.numpy() for e in embeddings])\n",
    "\n",
    "        combined_avg = tf.convert_to_tensor(np.mean(avg_embeddings, axis=0))\n",
    "        combined_max = tf.convert_to_tensor(np.max(max_embeddings, axis=0))\n",
    "\n",
    "        return Embedding(avg_embedding=combined_avg, max_embedding=combined_max)\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "def to_example(patient_id, data):\n",
    "    # Parse metadata\n",
    "    patient_info = data[\"patient_info\"][0]\n",
    "    label = patient_info[\"label\"]\n",
    "    center_id = patient_info[\"center_id\"]\n",
    "    image_ids = patient_info[\"image_ids\"]\n",
    "\n",
    "    # Parse embeddings (assume one Embedding object in list)\n",
    "    embedding = data[\"embeddings\"][0]\n",
    "    avg_emb = embedding.avg_embedding.numpy().tolist()\n",
    "    max_emb = embedding.max_embedding.numpy().tolist()\n",
    "\n",
    "    # Build tf.train.Example\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                \"patient_id\": _bytes_feature(patient_id),\n",
    "                \"label\": _bytes_feature(label),\n",
    "                \"center_id\": _bytes_feature(center_id),\n",
    "                \"image_ids\": _bytes_feature(\",\".join(image_ids)),\n",
    "                \"avg_embedding\": _float_feature(avg_emb),\n",
    "                \"max_embedding\": _float_feature(max_emb),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    print(f\">> TfExample: {example}\")\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    with open(csv_path, 'r') as f:\n",
    "        header_line = f.readline().strip()\n",
    "        header = header_line.split(',')\n",
    "        \n",
    "    with beam.Pipeline() as p:\n",
    "        csv_lines = p | \"ReadCSV\" >> beam.io.ReadFromText(csv_path, skip_header_lines=1)\n",
    "        parsed_row_dicts = csv_lines | beam.Map(lambda row: dict(zip(header, row.split(','))))\n",
    "        keyed_rows = parsed_row_dicts | beam.Map(key_patient_info)\n",
    "        patient_info = keyed_rows | beam.CombinePerKey(PatientDataCombineFn())\n",
    "        raw_tiles = keyed_rows | \"SelectImageId\" >> beam.MapTuple(select_image_id) | \"ProduceTiles\" >> beam.FlatMapTuple(produce_tiles, tiff_files_location)\n",
    "        \n",
    "        #splitting each large image into multiple smalled zoomed in tiles \n",
    "        #removing the black background from each image based on threshold\n",
    "        #loading selected tiles from whole images which are actually useful for downstream tasks\n",
    "        tile_entries = raw_tiles | beam.Map(convert_to_tile_entry)\n",
    "\n",
    "        #creating embeddings for the input tiles (creating max and avg embeddings using EfficientNet model)\n",
    "        embedded_tiles = tile_entries | \"EmbedTiles\" >> RunInference(TileEmbeddingModelHandler())\n",
    "        final_embeddings = embedded_tiles | \"KeyByPatientId\" >> beam.Map(lambda e: (e.patient_id, e)) | \"CombineEmbeddingsPerPatient\" >> beam.CombinePerKey(CombineEmbeddingsFn())\n",
    "\n",
    "        #combining everything together for richer data \n",
    "        merged_data = (\n",
    "            {\n",
    "                'patient_info': patient_info,\n",
    "                'embeddings': final_embeddings\n",
    "            }\n",
    "                | \"MergedData\" >> beam.CoGroupByKey()\n",
    "          ) \n",
    "        # | beam.Map(print)\n",
    "\n",
    "        #converting to tf train examples\n",
    "        examples = merged_data | \"ToTfExample\" >> beam.MapTuple(to_example)\n",
    "\n",
    "        #writing the outoput to TFRecord files used for downstream tensorflow tasks\n",
    "        examples | \"WriteTFRecords\" >> beam.io.tfrecordio.WriteToTFRecord(\n",
    "            file_path_prefix=output_prefix,\n",
    "            file_name_suffix=\".tfrecord\",\n",
    "            coder=beam.coders.ProtoCoder(tf.train.Example),\n",
    "        )\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
